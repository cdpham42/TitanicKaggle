{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TitanicKaggle\n",
    "Titanic Machine Learning Challenge from Kaggle\n",
    "\n",
    "From: https://www.kaggle.com/c/titanic\n",
    "\n",
    "## Competition Description\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n",
    "\n",
    "### Practice Skills\n",
    "Binary classification\n",
    "Python and R basics\n",
    "\n",
    "### Overview\n",
    "The data has been split into two groups:\n",
    "\n",
    "training set (train.csv)\n",
    "test set (test.csv)\n",
    "The training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the “ground truth”) for each passenger. Your model will be based on “features” like passengers’ gender and class. You can also use feature engineering to create new features.\n",
    "\n",
    "The test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.\n",
    "\n",
    "We also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import Modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import compress, product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Import Data\n",
    "\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "Here, I want to explore some basic characteristics of the dataset: population, number of survivors, characteristics of the survivors. Based on conventions at the time (i.e. prioritization of women and children), I predict that the passenger's sex, age, and class will play a large role in whether or not an individual survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n",
      "\n",
      "Count of People\n",
      " Sex\n",
      "female    312\n",
      "male      577\n",
      "Name: Embarked, dtype: int64\n",
      "\n",
      "Number of survivors: 342\n",
      "\n",
      "Number of survivors by sex:\n",
      " Sex\n",
      "female    233\n",
      "male      109\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cols = list(train_data.columns.values)\n",
    "print(cols)\n",
    "\n",
    "print(train_data.head())\n",
    "print(test_data.head())\n",
    "\n",
    "sex = train_data.groupby(\"Sex\").count()\n",
    "print(\"\\nCount of People\\n\",sex[\"Embarked\"])\n",
    "\n",
    "survived = train_data[\"Survived\"].sum()\n",
    "print(\"\\nNumber of survivors:\", survived)\n",
    "\n",
    "survived_sex = train_data.groupby(\"Sex\").sum()\n",
    "print(\"\\nNumber of survivors by sex:\\n\", survived_sex[\"Survived\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Prep\n",
    "\n",
    "\n",
    "Now I want to clean and prepare the data for use in the machine learning algorithms: removing/replacing NaN and empty data, removing columns that are now useful or useable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pclass  Sex   Age  SibSp  Parch\n",
      "0       3    1  22.0      1      0\n",
      "1       1    0  38.0      1      0\n",
      "2       3    0  26.0      0      0\n",
      "3       1    0  35.0      1      0\n",
      "4       3    1  35.0      0      0\n",
      "['Pclass', 'Sex', 'Age', 'SibSp', 'Parch']\n"
     ]
    }
   ],
   "source": [
    "# copy data so that making any mistake only needs to re-copy the original data, and not re-import all data.\n",
    "training = train_data\n",
    "\n",
    "# Map strings for female and male to 0 and 1\n",
    "mapping = {\"female\" : 0, \"male\" : 1}\n",
    "training = training.replace(mapping)\n",
    "\n",
    "# Fill Age NaNs with 0, as Age may be a good predictor\n",
    "training[\"Age\"] = training[\"Age\"].fillna(0)\n",
    "\n",
    "# Separate survived column into its own data\n",
    "survived = training[\"Survived\"]\n",
    "training = training.drop(\"Survived\", axis = 1)\n",
    "\n",
    "# Drop undesired columns\n",
    "training = training.drop([\"Name\", \"Cabin\", \"Ticket\", \"Fare\", \"Embarked\", \"PassengerId\"], axis =1)\n",
    "print(training.head())\n",
    "\n",
    "cols = list(training.columns.values)\n",
    "print(cols)\n",
    "\n",
    "# Get combinations of desired features\n",
    "\n",
    "def combinations(items):\n",
    "    return ( set(compress(items,mask)) for mask in product(*[[0,1]]*len(items)) )\n",
    "\n",
    "combos = list(combinations(cols))\n",
    "del combos[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinb(x, y):\n",
    "    \"\"\"\n",
    "    \n",
    "    This function performs the required functions for fitting and prediction a \n",
    "    Multinomial Naive Bayes\n",
    "    from given x and y datasets.\n",
    "    \n",
    "    Args:\n",
    "        x (array-like): independent data\n",
    "        y (array-like): target data\n",
    "        \n",
    "    Return:\n",
    "        score (float): Mean accuracy of the model on the given test and target \n",
    "        data\n",
    "    \n",
    "    \"\"\"\n",
    "    # Train Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.33,\n",
    "                                                        random_state = 0)\n",
    "    #X_train = np.array(X_train).reshape(-1,1)\n",
    "    y_train = np.array(y_train).reshape(-1,1)\n",
    "    #X_test = np.array(X_test).reshape(-1,1)\n",
    "    y_test = np.array(y_test).reshape(-1,1)\n",
    "    \n",
    "    y_train.reshape(-1,1)\n",
    "    \n",
    "    # Fit and predict model\n",
    "    multinb = MultinomialNB()\n",
    "    multinb.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    predicted = multinb.predict(X_test)\n",
    "    predicted\n",
    "    \n",
    "    multinb.predict(X_test)\n",
    "    score = multinb.score(X_test, y_test)\n",
    "    \n",
    "    # Plot\n",
    "    # x_axis = range(len(X_test))\n",
    "    #\n",
    "    # fig,ax = plt.subplots(figsize=(15,10))\n",
    "    # ax.scatter(x_axis, predicted, alpha = 0.3)\n",
    "    # ax.scatter(x_axis, y_test, alpha = 0.3)\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass : 0.6237288135593221\n",
      "Sex : 0.6237288135593221\n",
      "Age : 0.6237288135593221\n",
      "SibSp : 0.6237288135593221\n",
      "Parch : 0.6237288135593221\n"
     ]
    }
   ],
   "source": [
    "for col in cols:\n",
    "    try: \n",
    "        print(col, \":\", multinb(training[col], survived))\n",
    "    except:\n",
    "        print(\"Could not execute multinb for\", col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Parch'} : 0.6237288135593221\n",
      "{'SibSp'} : 0.6237288135593221\n",
      "{'SibSp', 'Parch'} : 0.6338983050847458\n",
      "{'Age'} : 0.6237288135593221\n",
      "{'Parch', 'Age'} : 0.6067796610169491\n",
      "{'SibSp', 'Age'} : 0.6237288135593221\n",
      "{'SibSp', 'Parch', 'Age'} : 0.6338983050847458\n",
      "{'Sex'} : 0.6237288135593221\n",
      "{'Sex', 'Parch'} : 0.6745762711864407\n",
      "{'Sex', 'SibSp'} : 0.6033898305084746\n",
      "{'Sex', 'SibSp', 'Parch'} : 0.6610169491525424\n",
      "{'Sex', 'Age'} : 0.7288135593220338\n",
      "{'Sex', 'Parch', 'Age'} : 0.7322033898305085\n",
      "{'Sex', 'SibSp', 'Age'} : 0.7016949152542373\n",
      "{'Sex', 'SibSp', 'Parch', 'Age'} : 0.7220338983050848\n",
      "{'Pclass'} : 0.6237288135593221\n",
      "{'Parch', 'Pclass'} : 0.6305084745762712\n",
      "{'SibSp', 'Pclass'} : 0.6237288135593221\n",
      "{'SibSp', 'Parch', 'Pclass'} : 0.6406779661016949\n",
      "{'Age', 'Pclass'} : 0.6406779661016949\n",
      "{'Age', 'Parch', 'Pclass'} : 0.6305084745762712\n",
      "{'SibSp', 'Age', 'Pclass'} : 0.6237288135593221\n",
      "{'SibSp', 'Age', 'Parch', 'Pclass'} : 0.6372881355932203\n",
      "{'Sex', 'Pclass'} : 0.6237288135593221\n",
      "{'Sex', 'Parch', 'Pclass'} : 0.6745762711864407\n",
      "{'Sex', 'SibSp', 'Pclass'} : 0.6101694915254238\n",
      "{'Sex', 'SibSp', 'Parch', 'Pclass'} : 0.6745762711864407\n",
      "{'Sex', 'Age', 'Pclass'} : 0.688135593220339\n",
      "{'Sex', 'Age', 'Parch', 'Pclass'} : 0.7084745762711865\n",
      "{'Sex', 'SibSp', 'Age', 'Pclass'} : 0.6745762711864407\n",
      "{'Sex', 'SibSp', 'Parch', 'Pclass', 'Age'} : 0.6915254237288135\n"
     ]
    }
   ],
   "source": [
    "for combo in combos:\n",
    "    #try:\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for c in combo:\n",
    "        df = pd.concat([df, training[c]], axis = 1)\n",
    "        \n",
    "    print(combo, \":\", multinb(df, survived))\n",
    "    \n",
    "    #except:\n",
    "        #print(\"Could not execute multinb for\", combo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
